{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Aamir Gulzar\\\\KSA_project2\\\\Cancer-detection-classifier\\\\feature_extraction'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction using Resnet-18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNextImageProcessor {\n",
      "  \"crop_pct\": 0.875,\n",
      "  \"do_normalize\": true,\n",
      "  \"do_rescale\": true,\n",
      "  \"do_resize\": true,\n",
      "  \"image_mean\": [\n",
      "    0.485,\n",
      "    0.456,\n",
      "    0.406\n",
      "  ],\n",
      "  \"image_processor_type\": \"ConvNextImageProcessor\",\n",
      "  \"image_std\": [\n",
      "    0.229,\n",
      "    0.224,\n",
      "    0.225\n",
      "  ],\n",
      "  \"resample\": 3,\n",
      "  \"rescale_factor\": 0.00392156862745098,\n",
      "  \"size\": {\n",
      "    \"shortest_edge\": 224\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoImageProcessor, AutoModel\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "from typing import Union, List\n",
    "import os\n",
    "\n",
    "class ResNetFeatureExtractor:\n",
    "    def __init__(self, model_name: str = \"microsoft/resnet-18\"):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.processor = AutoImageProcessor.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name).to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "    def extract_features(self, \n",
    "                         images: Union[str, Image.Image, List[str], List[Image.Image]], \n",
    "                         batch_size: int = 32) -> np.ndarray:\n",
    "        if isinstance(images, (str, Image.Image)):\n",
    "            images = [images]\n",
    "\n",
    "        # Load and preprocess images\n",
    "        all_features = []\n",
    "        image_batch = []\n",
    "        \n",
    "        for img in images:\n",
    "            if isinstance(img, str):\n",
    "                pil_img = Image.open(img).convert(\"RGB\")\n",
    "            elif isinstance(img, Image.Image):\n",
    "                pil_img = img.convert(\"RGB\")\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported image type: {type(img)}\")\n",
    "\n",
    "            image_batch.append(pil_img)\n",
    "\n",
    "        # Process in batches\n",
    "        for i in range(0, len(image_batch), batch_size):\n",
    "            batch_imgs = image_batch[i:i + batch_size]\n",
    "            inputs = self.processor(batch_imgs, return_tensors=\"pt\").to(self.device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(**inputs)\n",
    "                feats = outputs.last_hidden_state  # (B, C, 1, 1) ‚Üí (B, C)\n",
    "                # # Use the pooled output (e.g., CLS token)\n",
    "                # if hasattr(outputs, 'pooler_output'):  # For models like ViT\n",
    "                #     feats = outputs.pooler_output\n",
    "                # else:  # For resnet18, use last_hidden_state average\n",
    "                #     feats = outputs.last_hidden_state.squeeze(-1).squeeze(-1)  # (B, C, 1, 1) ‚Üí (B, C)\n",
    "\n",
    "            all_features.append(feats.cpu().numpy())\n",
    "\n",
    "        return np.concatenate(all_features, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from h5py import File as H5File\n",
    "from transformers import AutoModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "def run_full_pipeline(\n",
    "    patch_data_dir: str,\n",
    "    extractor,\n",
    "    slide_meta_csv: str,\n",
    "    non_white_csv: str,\n",
    "    output_root: str,\n",
    "    batch_size: int = 64\n",
    "):\n",
    "    # Load slide metadata and non-white patch names\n",
    "    slide_meta_df = pd.read_csv(slide_meta_csv)\n",
    "    non_white_df = pd.read_csv(non_white_csv)\n",
    "    valid_patch_names = set(non_white_df['patch_name'].astype(str))\n",
    "\n",
    "    # Iterate through all slide folders in patch_data_dir\n",
    "    slide_dirs = glob.glob(os.path.join(patch_data_dir, \"*\"))\n",
    "\n",
    "    for slide_dir in slide_dirs:\n",
    "        slide_name = os.path.basename(slide_dir)\n",
    "        print(f\"\\nProcessing slide: {slide_name}\")\n",
    "\n",
    "        # Match objective power\n",
    "        meta_row = slide_meta_df[slide_meta_df[\"renamed\"].str.lower() == slide_name.lower()]\n",
    "        if meta_row.empty:\n",
    "            print(f\"  ‚ùå Skipped: Slide metadata not found for {slide_name}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            obj_power = int(meta_row.iloc[0][\"Objective Power\"])\n",
    "            patch_size_level0 = 1024 if obj_power == 40 else 512 if obj_power == 20 else None\n",
    "            if patch_size_level0 is None:\n",
    "                print(f\"  ‚ùå Unsupported objective power: {obj_power}\")\n",
    "                continue\n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ùå Error extracting objective power: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Filter valid patches for this slide\n",
    "        all_patches = glob.glob(os.path.join(slide_dir, \"*.png\"))\n",
    "        patch_paths = [p for p in all_patches if os.path.basename(p) in valid_patch_names]\n",
    "\n",
    "        if not patch_paths:\n",
    "            print(f\"  ‚ùå No valid non-white patches found for {slide_name}\")\n",
    "            continue\n",
    "\n",
    "        # Sort and extract features\n",
    "        patch_paths = sort_by_coords(patch_paths)\n",
    "        output_dir = os.path.join(output_root, slide_name)\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        features_list = []\n",
    "        for i in range(0, len(patch_paths), batch_size):\n",
    "            batch_paths = patch_paths[i:i + batch_size]\n",
    "            try:\n",
    "                feats = extractor.extract_features(batch_paths, batch_size=batch_size)  # RESNET\n",
    "                features_list.append(feats)\n",
    "            except Exception as e:\n",
    "                print(f\"  ‚ö†Ô∏è Skipping batch due to error: {e}\")\n",
    "                continue\n",
    "\n",
    "        if not features_list:\n",
    "            print(f\"  ‚ùå No features extracted for {slide_name}\")\n",
    "            continue\n",
    "\n",
    "        features_np = np.concatenate(features_list, axis=0)\n",
    "        h5_path = create_h5_from_features(\n",
    "            features_np,\n",
    "            patch_paths,\n",
    "            output_dir=os.path.join(output_dir, \"patch_features\"),\n",
    "            slide_name=slide_name,\n",
    "            patch_size_level0=patch_size_level0\n",
    "        )\n",
    "\n",
    "        # Save a .pt version of the h5 contents\n",
    "        with H5File(h5_path, 'r') as file:\n",
    "            patch_features = torch.from_numpy(file['features'][:])\n",
    "            patch_coords = torch.from_numpy(file['coords'][:])\n",
    "            patch_size_lv0 = file['coords'].attrs['patch_size_level0']\n",
    "        \n",
    "        pt_data = {\n",
    "            'features': patch_features,\n",
    "            'coords': patch_coords,\n",
    "            'patch_size_level0': patch_size_lv0\n",
    "        }\n",
    "        \n",
    "        pt_path = h5_path.replace('.h5', '.pt')\n",
    "        torch.save(pt_data, pt_path)\n",
    "        \n",
    "        print(f\"  üíæ Saved patch data to .pt at {pt_path}\")\n",
    "        \n",
    "        # # Extract slide embedding\n",
    "        # with H5File(h5_path, 'r') as file:\n",
    "        #     feats = torch.from_numpy(file['features'][:])\n",
    "        #     coords = torch.from_numpy(file['coords'][:])\n",
    "        #     patch_size_lv0 = file['coords'].attrs['patch_size_level0']\n",
    "\n",
    "        # with torch.autocast('cuda', torch.float16), torch.inference_mode():\n",
    "        #     slide_emb = titan.encode_slide_from_patch_features(feats, coords, patch_size_lv0)\n",
    "\n",
    "        # slide_emb_path = os.path.join(output_dir, \"slide_features\", f\"{slide_name}_slide_embedding.pt\")\n",
    "        # os.makedirs(os.path.dirname(slide_emb_path), exist_ok=True)\n",
    "        # torch.save(slide_emb, slide_emb_path)\n",
    "\n",
    "        # print(f\"  ‚úÖ Done: Saved H5 and slide embedding for {slide_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = ResNetFeatureExtractor()\n",
    "\n",
    "run_full_pipeline(\n",
    "    patch_data_dir=r\"D:\\Aamir Gulzar\\KSA_project2\\dataset\\Test_data\",\n",
    "    extractor=extractor,\n",
    "    slide_meta_csv=r\"D:\\Aamir Gulzar\\KSA_project2\\Cancer-detection-classifier\\feature_extraction\\slide_metadata_filtered.csv\",\n",
    "    non_white_csv=r\"D:\\Aamir Gulzar\\KSA_project2\\Cancer-detection-classifier\\feature_extraction\\final_merged_without_white.csv\",\n",
    "    output_root=r\"D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\Conch_v1_5_Missing\",\n",
    "    batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from h5py import File as H5File\n",
    "from tqdm import tqdm\n",
    "\n",
    "def run_full_pipeline_test(\n",
    "    patch_data_dir: str,\n",
    "    extractor,\n",
    "    slide_meta_csv: str,\n",
    "    non_white_csv: str,\n",
    "    output_root: str,\n",
    "    batch_size: int = 64\n",
    "):\n",
    "    # Load slide metadata and non-white patch names\n",
    "    slide_meta_df = pd.read_csv(slide_meta_csv)\n",
    "    non_white_df = pd.read_csv(non_white_csv)\n",
    "    valid_patch_names = set(non_white_df['patch_name'].astype(str))\n",
    "\n",
    "    # Iterate through all slide folders in patch_data_dir\n",
    "    slide_dirs = glob.glob(os.path.join(patch_data_dir, \"*\"))\n",
    "\n",
    "    for slide_dir in slide_dirs:\n",
    "        slide_name = os.path.basename(slide_dir)\n",
    "        print(f\"\\nProcessing slide: {slide_name}\")\n",
    "\n",
    "        # Match objective power\n",
    "        meta_row = slide_meta_df[slide_meta_df[\"renamed\"].str.lower() == slide_name.lower()]\n",
    "        if meta_row.empty:\n",
    "            print(f\"  ‚ùå Skipped: Slide metadata not found for {slide_name}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            obj_power = int(meta_row.iloc[0][\"Objective Power\"])\n",
    "            patch_size_level0 = 1024 if obj_power == 40 else 512 if obj_power == 20 else None\n",
    "            if patch_size_level0 is None:\n",
    "                print(f\"  ‚ùå Unsupported objective power: {obj_power}\")\n",
    "                continue\n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ùå Error extracting objective power: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Filter valid patches for this slide\n",
    "        all_patches = glob.glob(os.path.join(slide_dir, \"*.png\"))\n",
    "        patch_paths = [p for p in all_patches if os.path.basename(p) in valid_patch_names]\n",
    "\n",
    "        if not patch_paths:\n",
    "            print(f\"  ‚ùå No valid non-white patches found for {slide_name}\")\n",
    "            continue\n",
    "\n",
    "        # Sort and extract features\n",
    "        patch_paths = sort_by_coords(patch_paths)\n",
    "        output_dir = os.path.join(output_root, slide_name)\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        features_list = []\n",
    "        print(\"  üîç Extracting features:\")\n",
    "        for i in tqdm(range(0, len(patch_paths), batch_size)):\n",
    "            batch_paths = patch_paths[i:i + batch_size]\n",
    "            try:\n",
    "                feats = extractor.extract_features(batch_paths, batch_size=batch_size)  # RESNET\n",
    "                features_list.append(feats)\n",
    "                print(f\"    ‚úÖ Batch {i//batch_size}: {feats.shape}\")\n",
    "            except Exception as e:\n",
    "                print(f\"    ‚ö†Ô∏è Skipping batch {i//batch_size} due to error: {e}\")\n",
    "                continue\n",
    "\n",
    "        if not features_list:\n",
    "            print(f\"  ‚ùå No features extracted for {slide_name}\")\n",
    "            continue\n",
    "\n",
    "        features_np = np.concatenate(features_list, axis=0)\n",
    "        print(f\"  üìê Feature shape for {slide_name}: {features_np.shape}\")\n",
    "\n",
    "        h5_path = create_h5_from_features(\n",
    "            features_np,\n",
    "            patch_paths,\n",
    "            output_dir=os.path.join(output_dir, \"patch_features\"),\n",
    "            slide_name=slide_name,\n",
    "            patch_size_level0=patch_size_level0\n",
    "        )\n",
    "        print(f\"  üíæ Saved H5 file at: {h5_path}\")\n",
    "\n",
    "        with H5File(h5_path, 'r') as file:\n",
    "            patch_features = torch.from_numpy(file['features'][:])\n",
    "            patch_coords = torch.from_numpy(file['coords'][:])\n",
    "            patch_size_lv0 = file['coords'].attrs['patch_size_level0']\n",
    "\n",
    "        print(f\"  üîç Loaded back features shape: {patch_features.shape}\")\n",
    "        print(f\"  üìç Coords shape: {patch_coords.shape}, Patch size: {patch_size_lv0}\")\n",
    "\n",
    "        pt_data = {\n",
    "            'features': patch_features,\n",
    "            'coords': patch_coords,\n",
    "            'patch_size_level0': patch_size_lv0\n",
    "        }\n",
    "\n",
    "        pt_path = h5_path.replace('.h5', '.pt')\n",
    "        torch.save(pt_data, pt_path)\n",
    "        print(f\"  üíæ Saved .pt at: {pt_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing slide: TCGA-3L-AA1B_nonMSIH\n",
      "  üîç Extracting features:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ‚úÖ Batch 0: (2, 512, 7, 7)\n",
      "  üìê Feature shape for TCGA-3L-AA1B_nonMSIH: (2, 512, 7, 7)\n",
      "H5 file created successfully: D:\\DataInsight\\CRC100k\\output_dir\\TCGA-3L-AA1B_nonMSIH\\patch_features\\TCGA-3L-AA1B_nonMSIH_patch_features.h5\n",
      "Features shape: (2, 512, 7, 7)\n",
      "Coords shape: (1, 2, 2)\n",
      "  üíæ Saved H5 file at: D:\\DataInsight\\CRC100k\\output_dir\\TCGA-3L-AA1B_nonMSIH\\patch_features\\TCGA-3L-AA1B_nonMSIH_patch_features.h5\n",
      "  üîç Loaded back features shape: torch.Size([2, 512, 7, 7])\n",
      "  üìç Coords shape: torch.Size([1, 2, 2]), Patch size: 1024\n",
      "  üíæ Saved .pt at: D:\\DataInsight\\CRC100k\\output_dir\\TCGA-3L-AA1B_nonMSIH\\patch_features\\TCGA-3L-AA1B_nonMSIH_patch_features.pt\n",
      "\n",
      "Processing slide: TCGA-A6-5661_MSIH\n",
      "  üîç Extracting features:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ‚úÖ Batch 0: (2, 512, 7, 7)\n",
      "  üìê Feature shape for TCGA-A6-5661_MSIH: (2, 512, 7, 7)\n",
      "H5 file created successfully: D:\\DataInsight\\CRC100k\\output_dir\\TCGA-A6-5661_MSIH\\patch_features\\TCGA-A6-5661_MSIH_patch_features.h5\n",
      "Features shape: (2, 512, 7, 7)\n",
      "Coords shape: (1, 2, 2)\n",
      "  üíæ Saved H5 file at: D:\\DataInsight\\CRC100k\\output_dir\\TCGA-A6-5661_MSIH\\patch_features\\TCGA-A6-5661_MSIH_patch_features.h5\n",
      "  üîç Loaded back features shape: torch.Size([2, 512, 7, 7])\n",
      "  üìç Coords shape: torch.Size([1, 2, 2]), Patch size: 1024\n",
      "  üíæ Saved .pt at: D:\\DataInsight\\CRC100k\\output_dir\\TCGA-A6-5661_MSIH\\patch_features\\TCGA-A6-5661_MSIH_patch_features.pt\n",
      "\n",
      "Processing slide: TCGA-AA-3846_nonMSIH\n",
      "  üîç Extracting features:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ‚úÖ Batch 0: (1, 512, 7, 7)\n",
      "  üìê Feature shape for TCGA-AA-3846_nonMSIH: (1, 512, 7, 7)\n",
      "H5 file created successfully: D:\\DataInsight\\CRC100k\\output_dir\\TCGA-AA-3846_nonMSIH\\patch_features\\TCGA-AA-3846_nonMSIH_patch_features.h5\n",
      "Features shape: (1, 512, 7, 7)\n",
      "Coords shape: (1, 1, 2)\n",
      "  üíæ Saved H5 file at: D:\\DataInsight\\CRC100k\\output_dir\\TCGA-AA-3846_nonMSIH\\patch_features\\TCGA-AA-3846_nonMSIH_patch_features.h5\n",
      "  üîç Loaded back features shape: torch.Size([1, 512, 7, 7])\n",
      "  üìç Coords shape: torch.Size([1, 1, 2]), Patch size: 512\n",
      "  üíæ Saved .pt at: D:\\DataInsight\\CRC100k\\output_dir\\TCGA-AA-3846_nonMSIH\\patch_features\\TCGA-AA-3846_nonMSIH_patch_features.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "extractor = ResNetFeatureExtractor()\n",
    "\n",
    "# For Laptop testing\n",
    "run_full_pipeline_test(\n",
    "    patch_data_dir=r\"D:\\Titan_Project\\Test_data_smallest\",\n",
    "    extractor=extractor,\n",
    "    slide_meta_csv=r\"D:\\Titan_Project\\slide_metadata_filtered.csv\",\n",
    "    non_white_csv=r\"D:\\Titan_Project\\final_merged_without_white.csv\",\n",
    "    output_root=r\"D:\\DataInsight\\CRC100k\\output_dir\",\n",
    "    batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting H5 file: D:\\DataInsight\\CRC100k\\output_dir\\TCGA-3L-AA1B_nonMSIH\\patch_features\\TCGA-3L-AA1B_nonMSIH_patch_features.h5\n",
      "==================================================\n",
      "Dataset: coords\n",
      "  Shape: (1, 2, 2)\n",
      "  Dtype: int64\n",
      "  Attributes: {'contour_fn': 'four_pt', 'custom_downsample': 2.0, 'downsample': array([1., 1.]), 'name': 'TCGA-3L-AA1B_nonMSIH', 'patch_level': 0, 'patch_size': 1024, 'patch_size_level0': 1024, 'step_size': 1024, 'use_padding': True}\n",
      "\n",
      "Dataset: features\n",
      "  Shape: (2, 512, 7, 7)\n",
      "  Dtype: float32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def inspect_h5_file(h5_path):\n",
    "    \"\"\"Inspect the contents of an H5 file\"\"\"\n",
    "    print(f\"Inspecting H5 file: {h5_path}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    with h5py.File(h5_path, 'r') as file:\n",
    "        def print_structure(name, obj):\n",
    "            if isinstance(obj, h5py.Dataset):\n",
    "                print(f\"Dataset: {name}\")\n",
    "                print(f\"  Shape: {obj.shape}\")\n",
    "                print(f\"  Dtype: {obj.dtype}\")\n",
    "                if hasattr(obj, 'attrs') and len(obj.attrs) > 0:\n",
    "                    print(f\"  Attributes: {dict(obj.attrs)}\")\n",
    "                print()\n",
    "            elif isinstance(obj, h5py.Group):\n",
    "                print(f\"Group: {name}\")\n",
    "                if hasattr(obj, 'attrs') and len(obj.attrs) > 0:\n",
    "                    print(f\"  Attributes: {dict(obj.attrs)}\")\n",
    "                print()\n",
    "        \n",
    "        file.visititems(print_structure)\n",
    "\n",
    "# First, inspect your H5 file\n",
    "# demo_h5_path = \"TCGA-PC-A5DK-01Z-00-DX1.C2D3BC09-411F-46CF-811B-FDBA7C2A295B.h5\"\n",
    "# h5_path = r\"D:\\Titan_Project\\Features_Tests\\3732_ResNet\\features\\h5_files\\TCGA-AG-3732-01Z-00-DX1.5EC57511-2B19-4005-BCA0-333C387C66E6.h5\"\n",
    "h5_path = r\"D:\\DataInsight\\CRC100k\\output_dir\\TCGA-3L-AA1B_nonMSIH\\patch_features\\TCGA-3L-AA1B_nonMSIH_patch_features.h5\"\n",
    "inspect_h5_file(h5_path)\n",
    "# inspect_h5_file(demo_h5_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing slide: TCGA-3L-AA1B_nonMSIH\n",
      "  üîç Extracting features:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BBBBBBBBBBBBBBBBBBBBBBBBBBBB\n",
      "    ‚úÖ Batch 0: (2, 512, 1, 1)\n",
      "  üìê Feature shape for TCGA-3L-AA1B_nonMSIH: (2, 512, 1, 1)\n",
      "  üíæ Saved H5 file at: D:\\DataInsight\\CRC100k\\output_dir\\TCGA-3L-AA1B_nonMSIH\\patch_features\\TCGA-3L-AA1B_nonMSIH.h5\n",
      "  üîç Loaded back features shape: torch.Size([2, 512, 1, 1])\n",
      "  üìç Coords shape: torch.Size([2, 2]), Patch size: 1024\n",
      "  üíæ Saved .pt at: D:\\DataInsight\\CRC100k\\output_dir\\TCGA-3L-AA1B_nonMSIH\\patch_features\\TCGA-3L-AA1B_nonMSIH.pt\n",
      "\n",
      "Processing slide: TCGA-A6-5661_MSIH\n",
      "  üîç Extracting features:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BBBBBBBBBBBBBBBBBBBBBBBBBBBB\n",
      "    ‚úÖ Batch 0: (2, 512, 1, 1)\n",
      "  üìê Feature shape for TCGA-A6-5661_MSIH: (2, 512, 1, 1)\n",
      "  üíæ Saved H5 file at: D:\\DataInsight\\CRC100k\\output_dir\\TCGA-A6-5661_MSIH\\patch_features\\TCGA-A6-5661_MSIH.h5\n",
      "  üîç Loaded back features shape: torch.Size([2, 512, 1, 1])\n",
      "  üìç Coords shape: torch.Size([2, 2]), Patch size: 1024\n",
      "  üíæ Saved .pt at: D:\\DataInsight\\CRC100k\\output_dir\\TCGA-A6-5661_MSIH\\patch_features\\TCGA-A6-5661_MSIH.pt\n",
      "\n",
      "Processing slide: TCGA-AA-3846_nonMSIH\n",
      "  üîç Extracting features:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BBBBBBBBBBBBBBBBBBBBBBBBBBBB\n",
      "    ‚úÖ Batch 0: (1, 512, 1, 1)\n",
      "  üìê Feature shape for TCGA-AA-3846_nonMSIH: (1, 512, 1, 1)\n",
      "  üíæ Saved H5 file at: D:\\DataInsight\\CRC100k\\output_dir\\TCGA-AA-3846_nonMSIH\\patch_features\\TCGA-AA-3846_nonMSIH.h5\n",
      "  üîç Loaded back features shape: torch.Size([1, 512, 1, 1])\n",
      "  üìç Coords shape: torch.Size([1, 2]), Patch size: 512\n",
      "  üíæ Saved .pt at: D:\\DataInsight\\CRC100k\\output_dir\\TCGA-AA-3846_nonMSIH\\patch_features\\TCGA-AA-3846_nonMSIH.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from h5py import File as H5File\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoImageProcessor, AutoModel\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "from typing import Union, List\n",
    "import re\n",
    "\n",
    "class ResNetFeatureExtractor:\n",
    "    def __init__(self, model_name: str = \"microsoft/resnet-18\"):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.processor = AutoImageProcessor.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name).to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "    def extract_features(self, \n",
    "                         images: Union[str, Image.Image, List[str], List[Image.Image]], \n",
    "                         batch_size: int = 32) -> np.ndarray:\n",
    "        if isinstance(images, (str, Image.Image)):\n",
    "            images = [images]\n",
    "\n",
    "        # Load and preprocess images\n",
    "        all_features = []\n",
    "        image_batch = []\n",
    "        \n",
    "        for img in images:\n",
    "            if isinstance(img, str):\n",
    "                pil_img = Image.open(img).convert(\"RGB\")\n",
    "            elif isinstance(img, Image.Image):\n",
    "                pil_img = img.convert(\"RGB\")\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported image type: {type(img)}\")\n",
    "\n",
    "            image_batch.append(pil_img)\n",
    "\n",
    "        # Process in batches\n",
    "        for i in range(0, len(image_batch), batch_size):\n",
    "            batch_imgs = image_batch[i:i + batch_size]\n",
    "            inputs = self.processor(batch_imgs, return_tensors=\"pt\").to(self.device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(**inputs)\n",
    "                # Use the pooled output (e.g., CLS token)\n",
    "                if hasattr(outputs, 'pooler_output'):  # For models like ViT\n",
    "                    feats = outputs.pooler_output\n",
    "                else:  # For resnet18, use last_hidden_state average\n",
    "                    feats = outputs.last_hidden_state\n",
    "                    # Properly handle the spatial dimensions\n",
    "                    if len(feats.shape) == 4:  # (B, C, H, W)\n",
    "                        feats = feats.mean(dim=[2, 3])  # Global average pooling -> (B, C)\n",
    "                    elif len(feats.shape) == 3:  # (B, C, 1) - already mostly flattened\n",
    "                        feats = feats.squeeze(-1)  # (B, C)\n",
    "                    # If it's already 2D (B, C), leave as is\n",
    "\n",
    "            all_features.append(feats.cpu().numpy())\n",
    "\n",
    "        return np.concatenate(all_features, axis=0)\n",
    "\n",
    "def sort_by_coords(patch_paths):\n",
    "    \"\"\"Sort patch paths by their coordinates extracted from filename\"\"\"\n",
    "    def extract_coords(path):\n",
    "        filename = os.path.basename(path)\n",
    "        # Extract x, y coordinates from filename (adjust regex based on your naming convention)\n",
    "        # Common patterns: patch_x_y.png, slide_x_y.png, etc.\n",
    "        match = re.search(r'(\\d+)_(\\d+)', filename)\n",
    "        if match:\n",
    "            return int(match.group(1)), int(match.group(2))\n",
    "        return 0, 0\n",
    "    \n",
    "    return sorted(patch_paths, key=extract_coords)\n",
    "\n",
    "def create_h5_from_features(\n",
    "    features_np,\n",
    "    patch_paths,\n",
    "    output_dir,\n",
    "    slide_name,\n",
    "    patch_size_level0\n",
    "):\n",
    "    \"\"\"Create H5 file from features and patch paths\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    h5_path = os.path.join(output_dir, f\"{slide_name}.h5\")\n",
    "    \n",
    "    # Extract coordinates from patch paths\n",
    "    coords = []\n",
    "    for path in patch_paths:\n",
    "        filename = os.path.basename(path)\n",
    "        # Extract x, y coordinates from filename\n",
    "        match = re.search(r'(\\d+)_(\\d+)', filename)\n",
    "        if match:\n",
    "            x, y = int(match.group(1)), int(match.group(2))\n",
    "            coords.append([x, y])\n",
    "        else:\n",
    "            coords.append([0, 0])  # Default if no coords found\n",
    "    \n",
    "    coords_np = np.array(coords)  # Shape: (N, 2)\n",
    "    \n",
    "    # Save to H5 file\n",
    "    with H5File(h5_path, 'w') as file:\n",
    "        file.create_dataset('features', data=features_np)\n",
    "        coords_dataset = file.create_dataset('coords', data=coords_np)\n",
    "        coords_dataset.attrs['patch_size_level0'] = patch_size_level0\n",
    "    \n",
    "    return h5_path\n",
    "\n",
    "def run_full_pipeline_test(\n",
    "    patch_data_dir: str,\n",
    "    extractor,\n",
    "    slide_meta_csv: str,\n",
    "    non_white_csv: str,\n",
    "    output_root: str,\n",
    "    batch_size: int = 64\n",
    "):\n",
    "    # Load slide metadata and non-white patch names\n",
    "    slide_meta_df = pd.read_csv(slide_meta_csv)\n",
    "    non_white_df = pd.read_csv(non_white_csv)\n",
    "    valid_patch_names = set(non_white_df['patch_name'].astype(str))\n",
    "\n",
    "    # Iterate through all slide folders in patch_data_dir\n",
    "    slide_dirs = glob.glob(os.path.join(patch_data_dir, \"*\"))\n",
    "\n",
    "    for slide_dir in slide_dirs:\n",
    "        slide_name = os.path.basename(slide_dir)\n",
    "        print(f\"\\nProcessing slide: {slide_name}\")\n",
    "\n",
    "        # Match objective power\n",
    "        meta_row = slide_meta_df[slide_meta_df[\"renamed\"].str.lower() == slide_name.lower()]\n",
    "        if meta_row.empty:\n",
    "            print(f\"  ‚ùå Skipped: Slide metadata not found for {slide_name}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            obj_power = int(meta_row.iloc[0][\"Objective Power\"])\n",
    "            patch_size_level0 = 1024 if obj_power == 40 else 512 if obj_power == 20 else None\n",
    "            if patch_size_level0 is None:\n",
    "                print(f\"  ‚ùå Unsupported objective power: {obj_power}\")\n",
    "                continue\n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ùå Error extracting objective power: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Filter valid patches for this slide\n",
    "        all_patches = glob.glob(os.path.join(slide_dir, \"*.png\"))\n",
    "        patch_paths = [p for p in all_patches if os.path.basename(p) in valid_patch_names]\n",
    "\n",
    "        if not patch_paths:\n",
    "            print(f\"  ‚ùå No valid non-white patches found for {slide_name}\")\n",
    "            continue\n",
    "\n",
    "        # Sort and extract features\n",
    "        patch_paths = sort_by_coords(patch_paths)\n",
    "        output_dir = os.path.join(output_root, slide_name)\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        features_list = []\n",
    "        print(\"  üîç Extracting features:\")\n",
    "        for i in tqdm(range(0, len(patch_paths), batch_size)):\n",
    "            batch_paths = patch_paths[i:i + batch_size]\n",
    "            try:\n",
    "                feats = extractor.extract_features(batch_paths, batch_size=batch_size)\n",
    "                features_list.append(feats)\n",
    "                print(f\"    ‚úÖ Batch {i//batch_size}: {feats.shape}\")\n",
    "            except Exception as e:\n",
    "                print(f\"    ‚ö†Ô∏è Skipping batch {i//batch_size} due to error: {e}\")\n",
    "                continue\n",
    "\n",
    "        if not features_list:\n",
    "            print(f\"  ‚ùå No features extracted for {slide_name}\")\n",
    "            continue\n",
    "\n",
    "        features_np = np.concatenate(features_list, axis=0)\n",
    "        print(f\"  üìê Feature shape for {slide_name}: {features_np.shape}\")\n",
    "\n",
    "        h5_path = create_h5_from_features(\n",
    "            features_np,\n",
    "            patch_paths,\n",
    "            output_dir=os.path.join(output_dir, \"patch_features\"),\n",
    "            slide_name=slide_name,\n",
    "            patch_size_level0=patch_size_level0\n",
    "        )\n",
    "        print(f\"  üíæ Saved H5 file at: {h5_path}\")\n",
    "\n",
    "        # Load back and verify\n",
    "        with H5File(h5_path, 'r') as file:\n",
    "            patch_features = torch.from_numpy(file['features'][:])\n",
    "            patch_coords = torch.from_numpy(file['coords'][:])\n",
    "            patch_size_lv0 = file['coords'].attrs['patch_size_level0']\n",
    "\n",
    "        print(f\"  üîç Loaded back features shape: {patch_features.shape}\")\n",
    "        print(f\"  üìç Coords shape: {patch_coords.shape}, Patch size: {patch_size_lv0}\")\n",
    "\n",
    "        pt_data = {\n",
    "            'features': patch_features,\n",
    "            'coords': patch_coords,\n",
    "            'patch_size_level0': patch_size_lv0\n",
    "        }\n",
    "\n",
    "        pt_path = h5_path.replace('.h5', '.pt')\n",
    "        torch.save(pt_data, pt_path)\n",
    "        print(f\"  üíæ Saved .pt at: {pt_path}\")\n",
    "\n",
    "# Usage example:\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize extractor\n",
    "    extractor = ResNetFeatureExtractor()\n",
    "    \n",
    "    # For Laptop testing\n",
    "    run_full_pipeline_test(\n",
    "        patch_data_dir=r\"D:\\Titan_Project\\Test_data_smallest\",\n",
    "        extractor=extractor,\n",
    "        slide_meta_csv=r\"D:\\Titan_Project\\slide_metadata_filtered.csv\",\n",
    "        non_white_csv=r\"D:\\Titan_Project\\final_merged_without_white.csv\",\n",
    "        output_root=r\"D:\\DataInsight\\CRC100k\\output_dir\",\n",
    "        batch_size=64\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooled feature shape: torch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoImageProcessor, AutoModel\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "# Load image\n",
    "image_path = r\"D:\\DataInsight\\CRC100k\\Test_data_smallest\\TCGA-3L-AA1B_nonMSIH\\TCGA-3L-AA1B_nonMSIH_x2608_y14048_patch00000.png\"\n",
    "image = Image.open(image_path).convert(\"RGB\")  # Make sure it's in RGB\n",
    "\n",
    "# Load processor and model (for feature extraction)\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"microsoft/resnet-18\")\n",
    "model = AutoModel.from_pretrained(\"microsoft/resnet-18\")\n",
    "\n",
    "# Preprocess the image\n",
    "inputs = image_processor(image, return_tensors=\"pt\")\n",
    "\n",
    "# Get features (skip classification head)\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    features = outputs.last_hidden_state  # Should be [1, 512] for ResNet-18\n",
    "\n",
    "# If needed as a numpy array\n",
    "pooled_features = torch.nn.functional.adaptive_avg_pool2d(features, (1, 1)).squeeze()  # Shape: [512]\n",
    "print(\"Pooled feature shape:\", pooled_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda_3\\envs\\titan_env\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\miniconda_3\\envs\\titan_env\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 512, 1, 1])\n",
      "torch.Size([1, 512])\n",
      "Pooled feature shape: torch.Size([1, 512])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Load pre-trained ResNet18 from torchvision\n",
    "resnet18 = models.resnet18(pretrained=True)\n",
    "resnet18.eval()\n",
    "\n",
    "# Remove final classification layer (fc)\n",
    "backbone = torch.nn.Sequential(*(list(resnet18.children())[:-1]))  # Excludes the last FC layer\n",
    "\n",
    "# Image preprocessing (same as torchvision defaults)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "# Load and preprocess image\n",
    "image_path = r\"D:\\DataInsight\\CRC100k\\Test_data_smallest\\TCGA-3L-AA1B_nonMSIH\\TCGA-3L-AA1B_nonMSIH_x2608_y14048_patch00000.png\"\n",
    "image = Image.open(image_path).convert(\"RGB\")\n",
    "input_tensor = transform(image).unsqueeze(0)  # Shape: [1, 3, 224, 224]\n",
    "\n",
    "# Get pooled features directly\n",
    "with torch.no_grad():\n",
    "    features = backbone(input_tensor)  # Shape: [1, 512, 1, 1]\n",
    "    features = features.view(features.size(0), -1)  # Shape: [1, 512]\n",
    "\n",
    "print(\"Pooled feature shape:\", features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageClassification(\n",
      "    crop_size=[224]\n",
      "    resize_size=[256]\n",
      "    mean=[0.485, 0.456, 0.406]\n",
      "    std=[0.229, 0.224, 0.225]\n",
      "    interpolation=InterpolationMode.BILINEAR\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Check torchvision resnet preprocessing\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "\n",
    "# Load weights and their associated transforms\n",
    "weights = ResNet18_Weights.DEFAULT\n",
    "preprocess = weights.transforms()\n",
    "\n",
    "# View the actual transform pipeline\n",
    "print(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from typing import List, Tuple, Dict, Any\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "def extract_coords_from_filename(filename: str) -> Tuple[int, int]:\n",
    "    \"\"\"\n",
    "    Extract x, y coordinates from patch filename.\n",
    "    \n",
    "    Expected format: TCGA-AA-3846_nonMSIH_x3152_y22080_patch00015.png\n",
    "    \n",
    "    Args:\n",
    "        filename: Full filename or just the basename\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (x, y) coordinates\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If coordinates cannot be extracted from filename\n",
    "    \"\"\"\n",
    "    # Remove path and extension to get just the basename\n",
    "    basename = os.path.splitext(os.path.basename(filename))[0]\n",
    "    \n",
    "    # Pattern to match x and y coordinates\n",
    "    pattern = r'_x(\\d+)_y(\\d+)'\n",
    "    \n",
    "    match = re.search(pattern, basename)\n",
    "    if not match:\n",
    "        raise ValueError(f\"Could not extract coordinates from filename: {filename}\")\n",
    "    \n",
    "    x_coord = int(match.group(1))\n",
    "    y_coord = int(match.group(2))\n",
    "    \n",
    "    return x_coord, y_coord\n",
    "\n",
    "def sort_by_coords(image_paths: List[str]) -> List[str]:\n",
    "    def get_xy(path):\n",
    "        try:\n",
    "            return extract_coords_from_filename(path)\n",
    "        except ValueError:\n",
    "            return (float('inf'), float('inf'))  # Push invalid files to end\n",
    "    return sorted(image_paths, key=get_xy)\n",
    "\n",
    "def load_image_batch(image_paths: List[str], start_idx: int, batch_size: int, transform) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Load and transform a batch of images efficiently using threading.\n",
    "    \"\"\"\n",
    "    end_idx = min(start_idx + batch_size, len(image_paths))\n",
    "    batch_paths = image_paths[start_idx:end_idx]\n",
    "    \n",
    "    def load_single_image(path):\n",
    "        try:\n",
    "            img = Image.open(path).convert(\"RGB\")\n",
    "            return transform(img)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Failed to load {path}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    # Use threading for I/O bound image loading\n",
    "    with ThreadPoolExecutor(max_workers=min(8, len(batch_paths))) as executor:\n",
    "        tensors = list(executor.map(load_single_image, batch_paths))\n",
    "    \n",
    "    # Filter out None values and stack\n",
    "    valid_tensors = [t for t in tensors if t is not None]\n",
    "    if not valid_tensors:\n",
    "        return torch.empty(0)\n",
    "    \n",
    "    return torch.stack(valid_tensors)\n",
    "\n",
    "def create_h5_from_features(\n",
    "    features: np.ndarray,\n",
    "    image_paths: List[str],\n",
    "    output_dir: str,\n",
    "    slide_name: str = None,\n",
    "    patch_size_level0: int = 1024,\n",
    "    additional_attributes: Dict[str, Any] = None\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Create H5 file with features and coordinates extracted from image filenames.\n",
    "    \n",
    "    Args:\n",
    "        features: Feature array of shape (n_patches, feature_dim)\n",
    "        image_paths: List of image file paths corresponding to features\n",
    "        output_dir: Directory where to save the H5 file\n",
    "        slide_name: Name of the slide (extracted from first filename if None)\n",
    "        patch_size_level0: Patch size at level 0\n",
    "        additional_attributes: Additional attributes to add to coords dataset\n",
    "        \n",
    "    Returns:\n",
    "        Path to created H5 file\n",
    "    \"\"\"\n",
    "    if len(features) != len(image_paths):\n",
    "        raise ValueError(f\"Features length ({len(features)}) must match image_paths length ({len(image_paths)})\")\n",
    "    \n",
    "    # Extract coordinates from filenames using threading for speed\n",
    "    def extract_coords_worker(img_path):\n",
    "        try:\n",
    "            x, y = extract_coords_from_filename(img_path)\n",
    "            return [x, y]\n",
    "        except ValueError as e:\n",
    "            print(f\"Warning: {e}\")\n",
    "            return None\n",
    "    \n",
    "    # Parallel coordinate extraction\n",
    "    with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        coords_list = list(executor.map(extract_coords_worker, image_paths))\n",
    "    \n",
    "    # Filter out None values\n",
    "    coords = np.array([c for c in coords_list if c is not None], dtype=np.int64)\n",
    "    \n",
    "    # Extract slide name and label from first filename for H5 filename\n",
    "    if slide_name is None:\n",
    "        first_filename = os.path.basename(image_paths[0])\n",
    "        # Extract first 12 characters + label: TCGA-AA-3846_nonMSIH or TCGA-AA-3846_MSIH\n",
    "        parts = first_filename.split('_')\n",
    "        if len(parts) >= 2:\n",
    "            slide_name = '_'.join(parts[:2])  # e.g., \"TCGA-AA-3846_nonMSIH\"\n",
    "        else:\n",
    "            slide_name = parts[0]\n",
    "    \n",
    "    # Create H5 filename from slide name\n",
    "    h5_filename = f\"{slide_name}_patch_features.h5\"\n",
    "    output_path = os.path.join(output_dir, h5_filename)\n",
    "    \n",
    "    # Ensure features have the right shape (add batch dimension if needed)\n",
    "    if features.ndim == 2:\n",
    "        features = features[np.newaxis, :]  # Add batch dimension: (1, n_patches, feature_dim)\n",
    "    \n",
    "    # Ensure coords have the right shape\n",
    "    if coords.ndim == 2:\n",
    "        coords = coords[np.newaxis, :]  # Add batch dimension: (1, n_patches, 2)\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Create H5 file with optimized settings\n",
    "    with h5py.File(output_path, 'w') as h5f:\n",
    "        # Create features dataset with compression\n",
    "        features_dataset = h5f.create_dataset(\n",
    "            'features', \n",
    "            data=features.astype(np.float32),\n",
    "            dtype=np.float32,\n",
    "            compression='gzip',\n",
    "            compression_opts=1,  # Light compression for speed\n",
    "            chunks=True\n",
    "        )\n",
    "        \n",
    "        # Create coordinates dataset\n",
    "        coords_dataset = h5f.create_dataset(\n",
    "            'coords',\n",
    "            data=coords.astype(np.int64),\n",
    "            dtype=np.int64,\n",
    "            compression='gzip',\n",
    "            compression_opts=1,\n",
    "            chunks=True\n",
    "        )\n",
    "        \n",
    "        # Add attributes to coords dataset\n",
    "        default_attributes = {\n",
    "            'contour_fn': 'four_pt',\n",
    "            'custom_downsample': 2.0,\n",
    "            'downsample': np.array([1., 1.]),\n",
    "            'name': slide_name,\n",
    "            'patch_level': 0,\n",
    "            'patch_size': patch_size_level0,\n",
    "            'patch_size_level0': patch_size_level0,\n",
    "            'step_size': patch_size_level0,\n",
    "            'use_padding': True\n",
    "        }\n",
    "        \n",
    "        # Add additional attributes if provided\n",
    "        if additional_attributes:\n",
    "            default_attributes.update(additional_attributes)\n",
    "        \n",
    "        # Set attributes\n",
    "        for key, value in default_attributes.items():\n",
    "            coords_dataset.attrs[key] = value\n",
    "    \n",
    "    print(f\"H5 file created successfully: {output_path}\")\n",
    "    print(f\"Features shape: {features.shape}\")\n",
    "    print(f\"Coords shape: {coords.shape}\")\n",
    "    \n",
    "    return output_path\n",
    "\n",
    "def process_patch_directory_optimized(\n",
    "    patch_dir: str,\n",
    "    extractor,\n",
    "    output_dir: str,\n",
    "    csv_path: str,\n",
    "    batch_size: int = 64,  # Increased default batch size\n",
    "    file_pattern: str = \"*.png\",\n",
    "    patch_size_level0: int = 1024,\n",
    "    max_workers: int = 8,\n",
    "    progress_interval: int = 10\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Process all patches in a directory and create H5 file with optimizations.\n",
    "    \n",
    "    Args:\n",
    "        patch_dir: Directory containing patch images\n",
    "        extractor: ConchFeatureExtractor instance\n",
    "        output_dir: Directory for output H5 file\n",
    "        batch_size: Batch size for feature extraction (larger = faster)\n",
    "        file_pattern: File pattern to match (e.g., \"*.png\", \"*.jpg\")\n",
    "        patch_size_level0: Patch size at level 0\n",
    "        max_workers: Number of threads for image loading\n",
    "        progress_interval: Print progress every N batches\n",
    "        \n",
    "    Returns:\n",
    "        Path to created H5 file\n",
    "    \"\"\"\n",
    "    # Extract slide name from directory name\n",
    "    slide_name = os.path.basename(patch_dir.rstrip('/\\\\'))\n",
    "    \n",
    "    # Load Excel and find matching patch size\n",
    "    df_meta = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Find row where \"renamed\" matches slide_name (case-insensitive match)\n",
    "    row = df_meta[df_meta['renamed'].str.lower() == slide_name.lower()]\n",
    "    \n",
    "    if row.empty:\n",
    "        raise ValueError(f\"Slide name '{slide_name}' not found in csv file.\")\n",
    "    \n",
    "    objective_power = int(row.iloc[0]['Objective Power'])\n",
    "    if objective_power == 40:\n",
    "        patch_size_level0 = 1024\n",
    "    elif objective_power == 20:\n",
    "        patch_size_level0 = 512\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported objective power: {objective_power} for slide {slide_name}\")\n",
    "    \n",
    "    print(f\"Detected patch size: {patch_size_level0} for slide '{slide_name}' with objective power {objective_power}\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Get all image files\n",
    "    print(\"Scanning for images...\")\n",
    "    image_paths = glob.glob(os.path.join(patch_dir, file_pattern))\n",
    "    \n",
    "    if not image_paths:\n",
    "        raise ValueError(f\"No images found in {patch_dir} with pattern {file_pattern}\")\n",
    "    \n",
    "    # Sort paths for consistent ordering\n",
    "    image_paths = sort_by_coords(image_paths)\n",
    "    \n",
    "    print(f\"Found {len(image_paths)} images to process\")\n",
    "    print(f\"Using batch size: {batch_size}\")\n",
    "    print(f\"Estimated batches: {len(image_paths) // batch_size + 1}\")\n",
    "    \n",
    "    # Pre-allocate result arrays for better memory efficiency\n",
    "    n_images = len(image_paths)\n",
    "    feature_dim = None\n",
    "    all_features = []\n",
    "    \n",
    "    # Process in batches with optimized loading\n",
    "    print(\"Extracting features...\")\n",
    "    batch_count = 0\n",
    "    \n",
    "    for i in range(0, n_images, batch_size):\n",
    "        batch_start = time.time()\n",
    "        \n",
    "        # Load batch of images with threading\n",
    "        batch_tensor = load_image_batch(image_paths, i, batch_size, extractor.eval_transform)\n",
    "        \n",
    "        if batch_tensor.numel() == 0:\n",
    "            print(f\"Warning: Empty batch at index {i}\")\n",
    "            continue\n",
    "        \n",
    "        # Move to GPU and extract features\n",
    "        batch_tensor = batch_tensor.to(extractor.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            features = extractor.conch(batch_tensor)\n",
    "            features_np = features.cpu().numpy()\n",
    "            all_features.append(features_np)\n",
    "        \n",
    "        batch_count += 1\n",
    "        \n",
    "        # Progress reporting\n",
    "        if batch_count % progress_interval == 0:\n",
    "            batch_time = time.time() - batch_start\n",
    "            processed = min(i + batch_size, n_images)\n",
    "            elapsed = time.time() - start_time\n",
    "            rate = processed / elapsed\n",
    "            eta = (n_images - processed) / rate if rate > 0 else 0\n",
    "            \n",
    "            print(f\"Batch {batch_count}: {processed}/{n_images} images \"\n",
    "                  f\"({processed/n_images*100:.1f}%) - \"\n",
    "                  f\"Rate: {rate:.1f} imgs/sec - \"\n",
    "                  f\"ETA: {eta:.1f}s - \"\n",
    "                  f\"Batch time: {batch_time:.2f}s\")\n",
    "    \n",
    "    # Concatenate all features\n",
    "    if not all_features:\n",
    "        raise ValueError(\"No features extracted - check your images\")\n",
    "    \n",
    "    features = np.concatenate(all_features, axis=0)\n",
    "    \n",
    "    extraction_time = time.time() - start_time\n",
    "    print(f\"Feature extraction completed in {extraction_time:.2f}s\")\n",
    "    print(f\"Average rate: {len(image_paths)/extraction_time:.1f} images/sec\")\n",
    "    \n",
    "    # Create H5 file\n",
    "    print(\"Creating H5 file...\")\n",
    "    h5_start = time.time()\n",
    "    \n",
    "    h5_path = create_h5_from_features(\n",
    "        features=features,\n",
    "        image_paths=image_paths,\n",
    "        output_dir=output_dir,\n",
    "        patch_size_level0=patch_size_level0\n",
    "    )\n",
    "    \n",
    "    h5_time = time.time() - h5_start\n",
    "    total_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"H5 creation completed in {h5_time:.2f}s\")\n",
    "    print(f\"Total processing time: {total_time:.2f}s\")\n",
    "    print(f\"Overall rate: {len(image_paths)/total_time:.1f} images/sec\")\n",
    "    \n",
    "    return h5_path\n",
    "\n",
    "# Performance benchmarking function\n",
    "def benchmark_processing(\n",
    "    patch_dir: str,\n",
    "    extractor,\n",
    "    output_dir: str,\n",
    "    batch_sizes: List[int] = [32, 64, 128, 256]\n",
    ") -> Dict[int, float]:\n",
    "    \"\"\"\n",
    "    Benchmark different batch sizes to find optimal performance.\n",
    "    \n",
    "    Args:\n",
    "        patch_dir: Directory containing patch images\n",
    "        extractor: ConchFeatureExtractor instance\n",
    "        output_dir: Directory for output H5 file\n",
    "        batch_sizes: List of batch sizes to test\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary mapping batch_size to processing time\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # Get image count\n",
    "    image_paths = glob.glob(os.path.join(patch_dir, \"*.png\"))\n",
    "    n_images = len(image_paths)\n",
    "    \n",
    "    print(f\"Benchmarking with {n_images} images\")\n",
    "    \n",
    "    for batch_size in batch_sizes:\n",
    "        print(f\"\\nTesting batch size: {batch_size}\")\n",
    "        \n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Just test feature extraction (skip H5 creation for speed)\n",
    "            for i in range(0, min(n_images, 500), batch_size):  # Test first 500 images\n",
    "                batch_tensor = load_image_batch(image_paths, i, batch_size, extractor.eval_transform)\n",
    "                \n",
    "                if batch_tensor.numel() == 0:\n",
    "                    continue\n",
    "                \n",
    "                batch_tensor = batch_tensor.to(extractor.device)\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    features = extractor.conch(batch_tensor)\n",
    "                    _ = features.cpu().numpy()\n",
    "            \n",
    "            elapsed = time.time() - start_time\n",
    "            rate = min(500, n_images) / elapsed\n",
    "            \n",
    "            results[batch_size] = rate\n",
    "            print(f\"Batch size {batch_size}: {rate:.1f} images/sec\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Batch size {batch_size} failed: {e}\")\n",
    "            results[batch_size] = 0\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from typing import Union, List\n",
    "\n",
    "class ResNetFeatureExtractor:\n",
    "    def __init__(self):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        # Load pretrained torchvision ResNet-18 and remove final fc layer\n",
    "        resnet18 = models.resnet18(pretrained=True)\n",
    "        self.model = torch.nn.Sequential(*(list(resnet18.children())[:-1]))  # Exclude final FC\n",
    "        self.model = self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "        # Use standard ImageNet preprocessing\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]\n",
    "            )\n",
    "        ])\n",
    "\n",
    "    def extract_features(self, \n",
    "                         images: Union[str, Image.Image, List[str], List[Image.Image]], \n",
    "                         batch_size: int = 32) -> np.ndarray:\n",
    "        if isinstance(images, (str, Image.Image)):\n",
    "            images = [images]\n",
    "\n",
    "        all_features = []\n",
    "        image_batch = []\n",
    "\n",
    "        # Load and preprocess images\n",
    "        for img in images:\n",
    "            if isinstance(img, str):\n",
    "                pil_img = Image.open(img).convert(\"RGB\")\n",
    "            elif isinstance(img, Image.Image):\n",
    "                pil_img = img.convert(\"RGB\")\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported image type: {type(img)}\")\n",
    "\n",
    "            tensor = self.transform(pil_img)\n",
    "            image_batch.append(tensor)\n",
    "\n",
    "        # Batch processing\n",
    "        for i in range(0, len(image_batch), batch_size):\n",
    "            batch_tensor = torch.stack(image_batch[i:i + batch_size]).to(self.device)  # Shape: (B, 3, 224, 224)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                features = self.model(batch_tensor)  # Shape: (B, 512, 1, 1)\n",
    "                features = features.view(features.size(0), -1)  # Shape: (B, 512)\n",
    "\n",
    "            all_features.append(features.cpu().numpy())\n",
    "\n",
    "        return np.concatenate(all_features, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from h5py import File as H5File\n",
    "from transformers import AutoModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "def run_full_pipeline(\n",
    "    patch_data_dir: str,\n",
    "    extractor,\n",
    "    slide_meta_csv: str,\n",
    "    non_white_csv: str,\n",
    "    output_root: str,\n",
    "    batch_size: int = 64\n",
    "):\n",
    "    # Load slide metadata and non-white patch names\n",
    "    slide_meta_df = pd.read_csv(slide_meta_csv)\n",
    "    non_white_df = pd.read_csv(non_white_csv)\n",
    "    valid_patch_names = set(non_white_df['patch_name'].astype(str))\n",
    "\n",
    "    # Iterate through all slide folders in patch_data_dir\n",
    "    slide_dirs = glob.glob(os.path.join(patch_data_dir, \"*\"))\n",
    "\n",
    "    for slide_dir in slide_dirs:\n",
    "        slide_name = os.path.basename(slide_dir)\n",
    "\n",
    "        output_dir = os.path.join(output_root, slide_name)\n",
    "        if os.path.exists(output_dir):\n",
    "            print(f\"  ‚è≠Ô∏è Skipped: Output already exists for {slide_name}\")\n",
    "            continue\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        print(f\"\\nProcessing slide: {slide_name}\")\n",
    "\n",
    "        # Match objective power\n",
    "        meta_row = slide_meta_df[slide_meta_df[\"renamed\"].str.lower() == slide_name.lower()]\n",
    "        if meta_row.empty:\n",
    "            print(f\"  ‚ùå Skipped: Slide metadata not found for {slide_name}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            obj_power = int(meta_row.iloc[0][\"Objective Power\"])\n",
    "            patch_size_level0 = 1024 if obj_power == 40 else 512 if obj_power == 20 else None\n",
    "            if patch_size_level0 is None:\n",
    "                print(f\"  ‚ùå Unsupported objective power: {obj_power}\")\n",
    "                continue\n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ùå Error extracting objective power: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Filter valid patches for this slide\n",
    "        all_patches = glob.glob(os.path.join(slide_dir, \"*.png\"))\n",
    "        patch_paths = [p for p in all_patches if os.path.basename(p) in valid_patch_names]\n",
    "\n",
    "        if not patch_paths:\n",
    "            print(f\"  ‚ùå No valid non-white patches found for {slide_name}\")\n",
    "            continue\n",
    "\n",
    "        # Sort and extract features\n",
    "        patch_paths = sort_by_coords(patch_paths)\n",
    "\n",
    "        features_list = []\n",
    "        for i in range(0, len(patch_paths), batch_size):\n",
    "            batch_paths = patch_paths[i:i + batch_size]\n",
    "            try:\n",
    "                feats = extractor.extract_features(batch_paths, batch_size=batch_size)  # RESNET\n",
    "                features_list.append(feats)\n",
    "            except Exception as e:\n",
    "                print(f\"  ‚ö†Ô∏è Skipping batch due to error: {e}\")\n",
    "                continue\n",
    "\n",
    "        if not features_list:\n",
    "            print(f\"  ‚ùå No features extracted for {slide_name}\")\n",
    "            continue\n",
    "\n",
    "        features_np = np.concatenate(features_list, axis=0)\n",
    "        h5_path = create_h5_from_features(\n",
    "            features_np,\n",
    "            patch_paths,\n",
    "            output_dir=output_dir,\n",
    "            slide_name=slide_name,\n",
    "            patch_size_level0=patch_size_level0\n",
    "        )\n",
    "\n",
    "        # Save a .pt version of the h5 contents\n",
    "        with H5File(h5_path, 'r') as file:\n",
    "            patch_features = torch.from_numpy(file['features'][:])\n",
    "            patch_coords = torch.from_numpy(file['coords'][:])\n",
    "            patch_size_lv0 = file['coords'].attrs['patch_size_level0']\n",
    "        \n",
    "        pt_data = {\n",
    "            'features': patch_features,\n",
    "            'coords': patch_coords,\n",
    "            'patch_size_level0': patch_size_lv0\n",
    "        }\n",
    "        \n",
    "        pt_path = h5_path.replace('.h5', '.pt')\n",
    "        torch.save(pt_data, pt_path)\n",
    "        \n",
    "        print(f\"  üíæ Saved patch data to .pt at {pt_path}\")\n",
    "        \n",
    "        # # Extract slide embedding\n",
    "        # with H5File(h5_path, 'r') as file:\n",
    "        #     feats = torch.from_numpy(file['features'][:])\n",
    "        #     coords = torch.from_numpy(file['coords'][:])\n",
    "        #     patch_size_lv0 = file['coords'].attrs['patch_size_level0']\n",
    "\n",
    "        # with torch.autocast('cuda', torch.float16), torch.inference_mode():\n",
    "        #     slide_emb = titan.encode_slide_from_patch_features(feats, coords, patch_size_lv0)\n",
    "\n",
    "        # slide_emb_path = os.path.join(output_dir, \"slide_features\", f\"{slide_name}_slide_embedding.pt\")\n",
    "        # os.makedirs(os.path.dirname(slide_emb_path), exist_ok=True)\n",
    "        # torch.save(slide_emb, slide_emb_path)\n",
    "\n",
    "        # print(f\"  ‚úÖ Done: Saved H5 and slide embedding for {slide_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\datainsight\\anaconda3\\envs\\exaonepath\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\datainsight\\anaconda3\\envs\\exaonepath\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-3L-AA1B_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-4N-A93T_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-5M-AAT4_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-5M-AAT6_MSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-5M-AATE_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-A6-2671_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-A6-2681_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-A6-2685_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-A6-2686_MSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-A6-3807_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-A6-4105_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-A6-4107_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-A6-5657_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-A6-5660_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-A6-5661_MSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-A6-5662_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-A6-5664_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-A6-5665_MSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-A6-5666_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-A6-5667_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-A6-6137_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-A6-6138_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-A6-6142_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-A6-6648_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-A6-6649_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-A6-6651_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-A6-6652_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-A6-6653_MSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-A6-6654_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-A6-A565_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-A6-A566_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-A6-A567_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-A6-A56B_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-3664_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-3666_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-3667_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-3673_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-3678_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-3679_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-3680_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-3681_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-3684_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-3688_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-3692_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-3693_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-3696_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-3715_MSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-3811_MSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-3812_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-3814_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-3818_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-3819_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-3821_MSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-3831_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-3833_MSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-3837_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-3842_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-3844_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-3845_MSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-3846_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-3848_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-3850_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-3851_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-3852_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-3854_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-3855_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-3856_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-3858_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-3864_MSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-3866_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-3867_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-3875_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-3877_MSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-3947_MSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-3949_MSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-3950_MSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-3952_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-3956_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-3966_MSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-3968_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-3971_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-3973_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-3975_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-3976_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-3979_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-3982_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-3984_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-3986_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-3989_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-3994_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-A010_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-A01P_MSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-A01R_MSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-A01S_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-A01T_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-A01V_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-A01X_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-A01Z_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-A024_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-A02E_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-A02F_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-A02H_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-A02O_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-A02Y_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-A03F_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AA-A03J_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AD-5900_MSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AD-6548_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AD-6888_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AD-6889_MSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AD-6890_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AD-6901_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AD-6963_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AD-6964_MSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AD-6965_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AD-A5EJ_MSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AD-A5EK_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AF-2687_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AF-2690_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AF-2693_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AF-3911_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AF-4110_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AF-6136_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AF-6655_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AF-6672_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AF-A56K_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AF-A56L_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AF-A56N_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AG-3726_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AG-3727_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AG-3878_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AG-3882_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AG-3883_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AG-3885_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AG-3887_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AG-3890_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AG-3892_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AG-3893_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AG-3894_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AG-3896_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AG-3898_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AG-3901_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AG-3902_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AG-3909_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AG-4001_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AG-4008_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AG-4015_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AG-4021_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AG-4022_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AG-A002_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AG-A008_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AG-A00C_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AG-A011_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AG-A015_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AG-A016_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AG-A01L_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AG-A01N_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AG-A01W_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AG-A01Y_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AG-A020_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AG-A026_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AG-A02N_MSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AG-A02X_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AH-6544_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AH-6547_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AH-6643_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AH-6644_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AH-6897_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AH-6903_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AM-5820_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AM-5821_MSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AU-3779_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AU-6004_MSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AY-4070_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AY-4071_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AY-5543_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AY-6196_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AY-6197_MSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AY-6386_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AY-A54L_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AY-A69D_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AY-A71X_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AY-A8YK_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AZ-4308_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AZ-4315_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AZ-4614_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AZ-4615_MSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AZ-4616_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AZ-4681_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AZ-4682_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AZ-5403_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AZ-5407_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AZ-6598_MSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AZ-6599_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AZ-6600_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AZ-6603_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AZ-6605_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-AZ-6606_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CA-5254_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CA-5255_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CA-5256_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CA-5796_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CA-5797_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CA-6715_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CA-6716_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CA-6717_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CA-6718_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CA-6719_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CI-6622_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CI-6624_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CK-4947_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CK-4948_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CK-4950_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CK-4951_MSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CK-4952_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CK-5912_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CK-5913_MSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CK-5914_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CK-5915_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CK-5916_MSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CK-6746_MSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CK-6747_MSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CK-6748_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CK-6751_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CL-4957_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CL-5917_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CL-5918_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CM-4743_MSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CM-4744_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CM-4746_MSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CM-4747_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CM-4750_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CM-4751_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CM-4752_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CM-5341_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CM-5344_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CM-5348_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CM-5349_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CM-5860_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CM-5861_MSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CM-5862_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CM-5863_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CM-5864_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CM-5868_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CM-6161_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CM-6162_MSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CM-6163_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CM-6164_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CM-6165_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CM-6166_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CM-6167_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CM-6168_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CM-6169_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CM-6170_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CM-6171_MSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CM-6172_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CM-6674_MSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CM-6675_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CM-6676_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CM-6677_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CM-6678_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-CM-6679_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-D5-5537_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-D5-5538_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-D5-5539_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-D5-5540_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-D5-5541_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-D5-6529_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-D5-6530_MSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-D5-6531_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-D5-6532_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-D5-6533_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-D5-6534_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-D5-6535_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-D5-6536_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-D5-6537_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-D5-6538_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-D5-6539_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-D5-6540_MSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-D5-6541_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-D5-6898_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-D5-6920_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-D5-6922_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-D5-6924_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-D5-6926_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-D5-6927_MSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-D5-6928_MSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-D5-6929_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-D5-6930_MSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-D5-6931_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-D5-6932_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-D5-7000_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-DC-4745_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-DC-4749_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-DC-5337_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-DC-5869_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-DC-6154_MSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-DC-6155_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-DC-6157_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-DC-6158_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-DC-6160_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-DC-6681_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-DC-6682_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-DC-6683_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-DM-A0X9_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-DM-A0XD_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-DM-A0XF_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-DM-A1D0_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-DM-A1D4_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-DM-A1D6_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-DM-A1D7_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-DM-A1D8_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-DM-A1D9_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-DM-A1DA_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-DM-A1DB_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-DM-A1HA_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-DM-A280_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-DM-A282_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-DM-A285_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-DM-A288_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-DM-A28A_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-DM-A28E_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-DM-A28F_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-DM-A28G_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-DM-A28H_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-DM-A28K_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-DM-A28M_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-DT-5265_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-DY-A0XA_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-DY-A1DC_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-DY-A1DD_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-DY-A1DF_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-DY-A1DG_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-EF-5830_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-EI-6506_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-EI-6507_MSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-EI-6508_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-EI-6509_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-EI-6510_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-EI-6511_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-EI-6512_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-EI-6513_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-EI-6514_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-EI-6881_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-EI-6882_MSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-EI-6883_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-EI-6884_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-EI-6885_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-EI-6917_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-EI-7002_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-EI-7004_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-F4-6459_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-F4-6460_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-F4-6461_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-F4-6463_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-F4-6569_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-F4-6570_MSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-F4-6703_MSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-F4-6704_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-F4-6805_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-F4-6806_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-F4-6807_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-F4-6808_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-F4-6809_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-F4-6854_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-F4-6855_nonMSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-F4-6856_MSIH\n",
      "  ‚è≠Ô∏è Skipped: Output already exists for TCGA-F5-6464_nonMSIH\n",
      "\n",
      "Processing slide: TCGA-F5-6465_nonMSIH\n",
      "H5 file created successfully: D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-F5-6465_nonMSIH\\TCGA-F5-6465_nonMSIH_patch_features.h5\n",
      "Features shape: (1, 2560, 512)\n",
      "Coords shape: (1, 2560, 2)\n",
      "  üíæ Saved patch data to .pt at D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-F5-6465_nonMSIH\\TCGA-F5-6465_nonMSIH_patch_features.pt\n",
      "\n",
      "Processing slide: TCGA-F5-6571_nonMSIH\n",
      "H5 file created successfully: D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-F5-6571_nonMSIH\\TCGA-F5-6571_nonMSIH_patch_features.h5\n",
      "Features shape: (1, 4197, 512)\n",
      "Coords shape: (1, 4197, 2)\n",
      "  üíæ Saved patch data to .pt at D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-F5-6571_nonMSIH\\TCGA-F5-6571_nonMSIH_patch_features.pt\n",
      "\n",
      "Processing slide: TCGA-F5-6702_nonMSIH\n",
      "H5 file created successfully: D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-F5-6702_nonMSIH\\TCGA-F5-6702_nonMSIH_patch_features.h5\n",
      "Features shape: (1, 2271, 512)\n",
      "Coords shape: (1, 2271, 2)\n",
      "  üíæ Saved patch data to .pt at D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-F5-6702_nonMSIH\\TCGA-F5-6702_nonMSIH_patch_features.pt\n",
      "\n",
      "Processing slide: TCGA-F5-6811_nonMSIH\n",
      "H5 file created successfully: D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-F5-6811_nonMSIH\\TCGA-F5-6811_nonMSIH_patch_features.h5\n",
      "Features shape: (1, 691, 512)\n",
      "Coords shape: (1, 691, 2)\n",
      "  üíæ Saved patch data to .pt at D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-F5-6811_nonMSIH\\TCGA-F5-6811_nonMSIH_patch_features.pt\n",
      "\n",
      "Processing slide: TCGA-F5-6814_nonMSIH\n",
      "H5 file created successfully: D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-F5-6814_nonMSIH\\TCGA-F5-6814_nonMSIH_patch_features.h5\n",
      "Features shape: (1, 3682, 512)\n",
      "Coords shape: (1, 3682, 2)\n",
      "  üíæ Saved patch data to .pt at D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-F5-6814_nonMSIH\\TCGA-F5-6814_nonMSIH_patch_features.pt\n",
      "\n",
      "Processing slide: TCGA-F5-6863_nonMSIH\n",
      "H5 file created successfully: D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-F5-6863_nonMSIH\\TCGA-F5-6863_nonMSIH_patch_features.h5\n",
      "Features shape: (1, 2985, 512)\n",
      "Coords shape: (1, 2985, 2)\n",
      "  üíæ Saved patch data to .pt at D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-F5-6863_nonMSIH\\TCGA-F5-6863_nonMSIH_patch_features.pt\n",
      "\n",
      "Processing slide: TCGA-F5-6864_nonMSIH\n",
      "H5 file created successfully: D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-F5-6864_nonMSIH\\TCGA-F5-6864_nonMSIH_patch_features.h5\n",
      "Features shape: (1, 1995, 512)\n",
      "Coords shape: (1, 1995, 2)\n",
      "  üíæ Saved patch data to .pt at D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-F5-6864_nonMSIH\\TCGA-F5-6864_nonMSIH_patch_features.pt\n",
      "\n",
      "Processing slide: TCGA-G4-6293_nonMSIH\n",
      "H5 file created successfully: D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-G4-6293_nonMSIH\\TCGA-G4-6293_nonMSIH_patch_features.h5\n",
      "Features shape: (1, 3430, 512)\n",
      "Coords shape: (1, 3430, 2)\n",
      "  üíæ Saved patch data to .pt at D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-G4-6293_nonMSIH\\TCGA-G4-6293_nonMSIH_patch_features.pt\n",
      "\n",
      "Processing slide: TCGA-G4-6294_nonMSIH\n",
      "H5 file created successfully: D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-G4-6294_nonMSIH\\TCGA-G4-6294_nonMSIH_patch_features.h5\n",
      "Features shape: (1, 4722, 512)\n",
      "Coords shape: (1, 4722, 2)\n",
      "  üíæ Saved patch data to .pt at D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-G4-6294_nonMSIH\\TCGA-G4-6294_nonMSIH_patch_features.pt\n",
      "\n",
      "Processing slide: TCGA-G4-6295_nonMSIH\n",
      "H5 file created successfully: D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-G4-6295_nonMSIH\\TCGA-G4-6295_nonMSIH_patch_features.h5\n",
      "Features shape: (1, 3726, 512)\n",
      "Coords shape: (1, 3726, 2)\n",
      "  üíæ Saved patch data to .pt at D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-G4-6295_nonMSIH\\TCGA-G4-6295_nonMSIH_patch_features.pt\n",
      "\n",
      "Processing slide: TCGA-G4-6297_nonMSIH\n",
      "H5 file created successfully: D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-G4-6297_nonMSIH\\TCGA-G4-6297_nonMSIH_patch_features.h5\n",
      "Features shape: (1, 5139, 512)\n",
      "Coords shape: (1, 5139, 2)\n",
      "  üíæ Saved patch data to .pt at D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-G4-6297_nonMSIH\\TCGA-G4-6297_nonMSIH_patch_features.pt\n",
      "\n",
      "Processing slide: TCGA-G4-6298_nonMSIH\n",
      "H5 file created successfully: D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-G4-6298_nonMSIH\\TCGA-G4-6298_nonMSIH_patch_features.h5\n",
      "Features shape: (1, 6051, 512)\n",
      "Coords shape: (1, 6051, 2)\n",
      "  üíæ Saved patch data to .pt at D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-G4-6298_nonMSIH\\TCGA-G4-6298_nonMSIH_patch_features.pt\n",
      "\n",
      "Processing slide: TCGA-G4-6299_nonMSIH\n",
      "H5 file created successfully: D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-G4-6299_nonMSIH\\TCGA-G4-6299_nonMSIH_patch_features.h5\n",
      "Features shape: (1, 4570, 512)\n",
      "Coords shape: (1, 4570, 2)\n",
      "  üíæ Saved patch data to .pt at D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-G4-6299_nonMSIH\\TCGA-G4-6299_nonMSIH_patch_features.pt\n",
      "\n",
      "Processing slide: TCGA-G4-6302_MSIH\n",
      "H5 file created successfully: D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-G4-6302_MSIH\\TCGA-G4-6302_MSIH_patch_features.h5\n",
      "Features shape: (1, 3046, 512)\n",
      "Coords shape: (1, 3046, 2)\n",
      "  üíæ Saved patch data to .pt at D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-G4-6302_MSIH\\TCGA-G4-6302_MSIH_patch_features.pt\n",
      "\n",
      "Processing slide: TCGA-G4-6303_nonMSIH\n",
      "H5 file created successfully: D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-G4-6303_nonMSIH\\TCGA-G4-6303_nonMSIH_patch_features.h5\n",
      "Features shape: (1, 2575, 512)\n",
      "Coords shape: (1, 2575, 2)\n",
      "  üíæ Saved patch data to .pt at D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-G4-6303_nonMSIH\\TCGA-G4-6303_nonMSIH_patch_features.pt\n",
      "\n",
      "Processing slide: TCGA-G4-6304_MSIH\n",
      "H5 file created successfully: D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-G4-6304_MSIH\\TCGA-G4-6304_MSIH_patch_features.h5\n",
      "Features shape: (1, 6078, 512)\n",
      "Coords shape: (1, 6078, 2)\n",
      "  üíæ Saved patch data to .pt at D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-G4-6304_MSIH\\TCGA-G4-6304_MSIH_patch_features.pt\n",
      "\n",
      "Processing slide: TCGA-G4-6306_nonMSIH\n",
      "H5 file created successfully: D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-G4-6306_nonMSIH\\TCGA-G4-6306_nonMSIH_patch_features.h5\n",
      "Features shape: (1, 3570, 512)\n",
      "Coords shape: (1, 3570, 2)\n",
      "  üíæ Saved patch data to .pt at D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-G4-6306_nonMSIH\\TCGA-G4-6306_nonMSIH_patch_features.pt\n",
      "\n",
      "Processing slide: TCGA-G4-6307_nonMSIH\n",
      "H5 file created successfully: D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-G4-6307_nonMSIH\\TCGA-G4-6307_nonMSIH_patch_features.h5\n",
      "Features shape: (1, 3781, 512)\n",
      "Coords shape: (1, 3781, 2)\n",
      "  üíæ Saved patch data to .pt at D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-G4-6307_nonMSIH\\TCGA-G4-6307_nonMSIH_patch_features.pt\n",
      "\n",
      "Processing slide: TCGA-G4-6309_MSIH\n",
      "H5 file created successfully: D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-G4-6309_MSIH\\TCGA-G4-6309_MSIH_patch_features.h5\n",
      "Features shape: (1, 3701, 512)\n",
      "Coords shape: (1, 3701, 2)\n",
      "  üíæ Saved patch data to .pt at D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-G4-6309_MSIH\\TCGA-G4-6309_MSIH_patch_features.pt\n",
      "\n",
      "Processing slide: TCGA-G4-6311_nonMSIH\n",
      "H5 file created successfully: D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-G4-6311_nonMSIH\\TCGA-G4-6311_nonMSIH_patch_features.h5\n",
      "Features shape: (1, 3294, 512)\n",
      "Coords shape: (1, 3294, 2)\n",
      "  üíæ Saved patch data to .pt at D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-G4-6311_nonMSIH\\TCGA-G4-6311_nonMSIH_patch_features.pt\n",
      "\n",
      "Processing slide: TCGA-G4-6315_nonMSIH\n",
      "H5 file created successfully: D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-G4-6315_nonMSIH\\TCGA-G4-6315_nonMSIH_patch_features.h5\n",
      "Features shape: (1, 4405, 512)\n",
      "Coords shape: (1, 4405, 2)\n",
      "  üíæ Saved patch data to .pt at D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-G4-6315_nonMSIH\\TCGA-G4-6315_nonMSIH_patch_features.pt\n",
      "\n",
      "Processing slide: TCGA-G4-6317_nonMSIH\n",
      "H5 file created successfully: D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-G4-6317_nonMSIH\\TCGA-G4-6317_nonMSIH_patch_features.h5\n",
      "Features shape: (1, 3555, 512)\n",
      "Coords shape: (1, 3555, 2)\n",
      "  üíæ Saved patch data to .pt at D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-G4-6317_nonMSIH\\TCGA-G4-6317_nonMSIH_patch_features.pt\n",
      "\n",
      "Processing slide: TCGA-G4-6320_MSIH\n",
      "H5 file created successfully: D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-G4-6320_MSIH\\TCGA-G4-6320_MSIH_patch_features.h5\n",
      "Features shape: (1, 2886, 512)\n",
      "Coords shape: (1, 2886, 2)\n",
      "  üíæ Saved patch data to .pt at D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-G4-6320_MSIH\\TCGA-G4-6320_MSIH_patch_features.pt\n",
      "\n",
      "Processing slide: TCGA-G4-6321_nonMSIH\n",
      "H5 file created successfully: D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-G4-6321_nonMSIH\\TCGA-G4-6321_nonMSIH_patch_features.h5\n",
      "Features shape: (1, 2814, 512)\n",
      "Coords shape: (1, 2814, 2)\n",
      "  üíæ Saved patch data to .pt at D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-G4-6321_nonMSIH\\TCGA-G4-6321_nonMSIH_patch_features.pt\n",
      "\n",
      "Processing slide: TCGA-G4-6322_nonMSIH\n",
      "H5 file created successfully: D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-G4-6322_nonMSIH\\TCGA-G4-6322_nonMSIH_patch_features.h5\n",
      "Features shape: (1, 4860, 512)\n",
      "Coords shape: (1, 4860, 2)\n",
      "  üíæ Saved patch data to .pt at D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-G4-6322_nonMSIH\\TCGA-G4-6322_nonMSIH_patch_features.pt\n",
      "\n",
      "Processing slide: TCGA-G4-6323_nonMSIH\n",
      "H5 file created successfully: D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-G4-6323_nonMSIH\\TCGA-G4-6323_nonMSIH_patch_features.h5\n",
      "Features shape: (1, 2648, 512)\n",
      "Coords shape: (1, 2648, 2)\n",
      "  üíæ Saved patch data to .pt at D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-G4-6323_nonMSIH\\TCGA-G4-6323_nonMSIH_patch_features.pt\n",
      "\n",
      "Processing slide: TCGA-G4-6586_MSIH\n",
      "H5 file created successfully: D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-G4-6586_MSIH\\TCGA-G4-6586_MSIH_patch_features.h5\n",
      "Features shape: (1, 3761, 512)\n",
      "Coords shape: (1, 3761, 2)\n",
      "  üíæ Saved patch data to .pt at D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-G4-6586_MSIH\\TCGA-G4-6586_MSIH_patch_features.pt\n",
      "\n",
      "Processing slide: TCGA-G4-6588_MSIH\n",
      "H5 file created successfully: D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-G4-6588_MSIH\\TCGA-G4-6588_MSIH_patch_features.h5\n",
      "Features shape: (1, 4272, 512)\n",
      "Coords shape: (1, 4272, 2)\n",
      "  üíæ Saved patch data to .pt at D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-G4-6588_MSIH\\TCGA-G4-6588_MSIH_patch_features.pt\n",
      "\n",
      "Processing slide: TCGA-G4-6626_nonMSIH\n",
      "H5 file created successfully: D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-G4-6626_nonMSIH\\TCGA-G4-6626_nonMSIH_patch_features.h5\n",
      "Features shape: (1, 3020, 512)\n",
      "Coords shape: (1, 3020, 2)\n",
      "  üíæ Saved patch data to .pt at D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-G4-6626_nonMSIH\\TCGA-G4-6626_nonMSIH_patch_features.pt\n",
      "\n",
      "Processing slide: TCGA-G4-6627_nonMSIH\n",
      "H5 file created successfully: D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-G4-6627_nonMSIH\\TCGA-G4-6627_nonMSIH_patch_features.h5\n",
      "Features shape: (1, 4823, 512)\n",
      "Coords shape: (1, 4823, 2)\n",
      "  üíæ Saved patch data to .pt at D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-G4-6627_nonMSIH\\TCGA-G4-6627_nonMSIH_patch_features.pt\n",
      "\n",
      "Processing slide: TCGA-G4-6628_MSIH\n",
      "H5 file created successfully: D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-G4-6628_MSIH\\TCGA-G4-6628_MSIH_patch_features.h5\n",
      "Features shape: (1, 4592, 512)\n",
      "Coords shape: (1, 4592, 2)\n",
      "  üíæ Saved patch data to .pt at D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-G4-6628_MSIH\\TCGA-G4-6628_MSIH_patch_features.pt\n",
      "\n",
      "Processing slide: TCGA-G5-6641_nonMSIH\n",
      "H5 file created successfully: D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-G5-6641_nonMSIH\\TCGA-G5-6641_nonMSIH_patch_features.h5\n",
      "Features shape: (1, 2376, 512)\n",
      "Coords shape: (1, 2376, 2)\n",
      "  üíæ Saved patch data to .pt at D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-G5-6641_nonMSIH\\TCGA-G5-6641_nonMSIH_patch_features.pt\n",
      "\n",
      "Processing slide: TCGA-NH-A50T_nonMSIH\n",
      "H5 file created successfully: D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-NH-A50T_nonMSIH\\TCGA-NH-A50T_nonMSIH_patch_features.h5\n",
      "Features shape: (1, 4445, 512)\n",
      "Coords shape: (1, 4445, 2)\n",
      "  üíæ Saved patch data to .pt at D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-NH-A50T_nonMSIH\\TCGA-NH-A50T_nonMSIH_patch_features.pt\n",
      "\n",
      "Processing slide: TCGA-NH-A50U_nonMSIH\n",
      "H5 file created successfully: D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-NH-A50U_nonMSIH\\TCGA-NH-A50U_nonMSIH_patch_features.h5\n",
      "Features shape: (1, 3411, 512)\n",
      "Coords shape: (1, 3411, 2)\n",
      "  üíæ Saved patch data to .pt at D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-NH-A50U_nonMSIH\\TCGA-NH-A50U_nonMSIH_patch_features.pt\n",
      "\n",
      "Processing slide: TCGA-NH-A50V_nonMSIH\n",
      "H5 file created successfully: D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-NH-A50V_nonMSIH\\TCGA-NH-A50V_nonMSIH_patch_features.h5\n",
      "Features shape: (1, 4077, 512)\n",
      "Coords shape: (1, 4077, 2)\n",
      "  üíæ Saved patch data to .pt at D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-NH-A50V_nonMSIH\\TCGA-NH-A50V_nonMSIH_patch_features.pt\n",
      "\n",
      "Processing slide: TCGA-NH-A5IV_MSIH\n",
      "H5 file created successfully: D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-NH-A5IV_MSIH\\TCGA-NH-A5IV_MSIH_patch_features.h5\n",
      "Features shape: (1, 4738, 512)\n",
      "Coords shape: (1, 4738, 2)\n",
      "  üíæ Saved patch data to .pt at D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-NH-A5IV_MSIH\\TCGA-NH-A5IV_MSIH_patch_features.pt\n",
      "\n",
      "Processing slide: TCGA-NH-A6GA_nonMSIH\n",
      "H5 file created successfully: D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-NH-A6GA_nonMSIH\\TCGA-NH-A6GA_nonMSIH_patch_features.h5\n",
      "Features shape: (1, 2918, 512)\n",
      "Coords shape: (1, 2918, 2)\n",
      "  üíæ Saved patch data to .pt at D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-NH-A6GA_nonMSIH\\TCGA-NH-A6GA_nonMSIH_patch_features.pt\n",
      "\n",
      "Processing slide: TCGA-NH-A6GB_nonMSIH\n",
      "H5 file created successfully: D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-NH-A6GB_nonMSIH\\TCGA-NH-A6GB_nonMSIH_patch_features.h5\n",
      "Features shape: (1, 5249, 512)\n",
      "Coords shape: (1, 5249, 2)\n",
      "  üíæ Saved patch data to .pt at D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-NH-A6GB_nonMSIH\\TCGA-NH-A6GB_nonMSIH_patch_features.pt\n",
      "\n",
      "Processing slide: TCGA-NH-A6GC_nonMSIH\n",
      "H5 file created successfully: D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-NH-A6GC_nonMSIH\\TCGA-NH-A6GC_nonMSIH_patch_features.h5\n",
      "Features shape: (1, 4013, 512)\n",
      "Coords shape: (1, 4013, 2)\n",
      "  üíæ Saved patch data to .pt at D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-NH-A6GC_nonMSIH\\TCGA-NH-A6GC_nonMSIH_patch_features.pt\n",
      "\n",
      "Processing slide: TCGA-NH-A8F8_nonMSIH\n",
      "H5 file created successfully: D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-NH-A8F8_nonMSIH\\TCGA-NH-A8F8_nonMSIH_patch_features.h5\n",
      "Features shape: (1, 4086, 512)\n",
      "Coords shape: (1, 4086, 2)\n",
      "  üíæ Saved patch data to .pt at D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-NH-A8F8_nonMSIH\\TCGA-NH-A8F8_nonMSIH_patch_features.pt\n",
      "\n",
      "Processing slide: TCGA-QG-A5YV_nonMSIH\n",
      "H5 file created successfully: D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-QG-A5YV_nonMSIH\\TCGA-QG-A5YV_nonMSIH_patch_features.h5\n",
      "Features shape: (1, 4699, 512)\n",
      "Coords shape: (1, 4699, 2)\n",
      "  üíæ Saved patch data to .pt at D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-QG-A5YV_nonMSIH\\TCGA-QG-A5YV_nonMSIH_patch_features.pt\n",
      "\n",
      "Processing slide: TCGA-QG-A5YW_nonMSIH\n",
      "H5 file created successfully: D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-QG-A5YW_nonMSIH\\TCGA-QG-A5YW_nonMSIH_patch_features.h5\n",
      "Features shape: (1, 3628, 512)\n",
      "Coords shape: (1, 3628, 2)\n",
      "  üíæ Saved patch data to .pt at D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-QG-A5YW_nonMSIH\\TCGA-QG-A5YW_nonMSIH_patch_features.pt\n",
      "\n",
      "Processing slide: TCGA-QG-A5YX_nonMSIH\n",
      "H5 file created successfully: D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-QG-A5YX_nonMSIH\\TCGA-QG-A5YX_nonMSIH_patch_features.h5\n",
      "Features shape: (1, 3727, 512)\n",
      "Coords shape: (1, 3727, 2)\n",
      "  üíæ Saved patch data to .pt at D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-QG-A5YX_nonMSIH\\TCGA-QG-A5YX_nonMSIH_patch_features.pt\n",
      "\n",
      "Processing slide: TCGA-QG-A5Z1_nonMSIH\n",
      "H5 file created successfully: D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-QG-A5Z1_nonMSIH\\TCGA-QG-A5Z1_nonMSIH_patch_features.h5\n",
      "Features shape: (1, 4144, 512)\n",
      "Coords shape: (1, 4144, 2)\n",
      "  üíæ Saved patch data to .pt at D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-QG-A5Z1_nonMSIH\\TCGA-QG-A5Z1_nonMSIH_patch_features.pt\n",
      "\n",
      "Processing slide: TCGA-QG-A5Z2_MSIH\n",
      "H5 file created successfully: D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-QG-A5Z2_MSIH\\TCGA-QG-A5Z2_MSIH_patch_features.h5\n",
      "Features shape: (1, 4849, 512)\n",
      "Coords shape: (1, 4849, 2)\n",
      "  üíæ Saved patch data to .pt at D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-QG-A5Z2_MSIH\\TCGA-QG-A5Z2_MSIH_patch_features.pt\n",
      "\n",
      "Processing slide: TCGA-QL-A97D_nonMSIH\n",
      "H5 file created successfully: D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-QL-A97D_nonMSIH\\TCGA-QL-A97D_nonMSIH_patch_features.h5\n",
      "Features shape: (1, 4126, 512)\n",
      "Coords shape: (1, 4126, 2)\n",
      "  üíæ Saved patch data to .pt at D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-QL-A97D_nonMSIH\\TCGA-QL-A97D_nonMSIH_patch_features.pt\n",
      "\n",
      "Processing slide: TCGA-SS-A7HO_nonMSIH\n",
      "H5 file created successfully: D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-SS-A7HO_nonMSIH\\TCGA-SS-A7HO_nonMSIH_patch_features.h5\n",
      "Features shape: (1, 5746, 512)\n",
      "Coords shape: (1, 5746, 2)\n",
      "  üíæ Saved patch data to .pt at D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-SS-A7HO_nonMSIH\\TCGA-SS-A7HO_nonMSIH_patch_features.pt\n",
      "\n",
      "Processing slide: TCGA-T9-A92H_nonMSIH\n",
      "H5 file created successfully: D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-T9-A92H_nonMSIH\\TCGA-T9-A92H_nonMSIH_patch_features.h5\n",
      "Features shape: (1, 5462, 512)\n",
      "Coords shape: (1, 5462, 2)\n",
      "  üíæ Saved patch data to .pt at D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-T9-A92H_nonMSIH\\TCGA-T9-A92H_nonMSIH_patch_features.pt\n",
      "\n",
      "Processing slide: TCGA-WS-AB45_MSIH\n",
      "H5 file created successfully: D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-WS-AB45_MSIH\\TCGA-WS-AB45_MSIH_patch_features.h5\n",
      "Features shape: (1, 4532, 512)\n",
      "Coords shape: (1, 4532, 2)\n",
      "  üíæ Saved patch data to .pt at D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\\TCGA-WS-AB45_MSIH\\TCGA-WS-AB45_MSIH_patch_features.pt\n"
     ]
    }
   ],
   "source": [
    "extractor = ResNetFeatureExtractor()\n",
    "\n",
    "run_full_pipeline(\n",
    "    patch_data_dir=r\"D:\\Aamir Gulzar\\KSA_project2\\dataset\\patch_data\",\n",
    "    extractor=extractor,\n",
    "    slide_meta_csv=r\"D:\\Aamir Gulzar\\KSA_project2\\Cancer-detection-classifier\\feature_extraction\\slide_metadata_filtered.csv\",\n",
    "    non_white_csv=r\"D:\\Aamir Gulzar\\KSA_project2\\Cancer-detection-classifier\\feature_extraction\\final_merged_without_white.csv\",\n",
    "    output_root=r\"D:\\Aamir Gulzar\\KSA_project2\\dataset\\Features\\ResNet_18\",\n",
    "    batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exaonepath",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
